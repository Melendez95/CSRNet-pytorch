{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DETECCION_Entrenamiento-Validacion.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "eOXC1C8x22e1",
        "SnwaFDi2EyfN",
        "5Xq3gFddkib6"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdmelendez/CSRNet-pytorch/blob/master/CNN/Object-Detection/DETECCION_Entrenamiento_Validacion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvvXEpBBmjgp",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "b2c6f940-4bc4-4cf7-e88b-01855127dddc"
      },
      "source": [
        "#@title ######ACCESO A GOOGLE DRIVE\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/3wH8KVGEeR0WOvoB2iilNbahInMprBsFsMMswkUonXT4Y6ee9StiBMs\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_S-eqFK_sfY6",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title ######CARGA LIBRERIAS \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import patches\n",
        "from matplotlib.patches import ConnectionPatch\n",
        " \n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "import torchvision\n",
        "from torchsummary import summary\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision import datasets, transforms, models, utils\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "torch.backends.cudnn.benchmarck = True\n",
        " \n",
        "import numpy as np\n",
        "import math \n",
        "import cv2\n",
        "import time\n",
        "import os,sys\n",
        "from PIL import Image\n",
        "import glob\n",
        "import xml.etree.cElementTree as ET\n",
        "import os\n",
        "import csv\n",
        "import pandas as pd\n",
        "import io\n",
        "from os.path import basename\n",
        "from pathlib import Path\n",
        "from random import randint, uniform,random\n",
        "from IPython.display import display\n",
        " \n",
        "from sklearn import metrics\n",
        "from sklearn import preprocessing\n",
        " \n",
        "np.random.seed(0)\n",
        "id = randint(0,1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPrp94qt5yVF",
        "colab_type": "text"
      },
      "source": [
        "# **MENÚ DE SELECCIÓN**\n",
        " \n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmOg5p1d5wON",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e1a18aa9-4c47-400b-90a2-a08433546ef4"
      },
      "source": [
        "#@title **ANÁLISIS - PATÓGENO:**\n",
        "# Parametros de carga de datos segun estructura de carpetas en Google Drive y expotacion a PDF:\n",
        "#tipo_analisis = \"Aguas - Deteccion\"\n",
        "#tipo_patogeno = \"Aerobios Mesofilos\"\n",
        "tipo_analisis = 'Aguas - Deteccion' #@param [\"Aguas - Deteccion\", \"Challenge - Deteccion\"]{allow-input: false}\n",
        "tipo_patogeno = 'Aerobios Mesofilos' #@param [\"Aspergillus Brasiliensis\",\"Burkholderia Cepacia\", \"Candida Albicans\",\"Escherichia Coli\",\"Pseudomonas Aeruginosa\",\"Staphylococcus Aureus\",\"Aerobios Mesofilos\",\"Mohos y levaduras\"]{allow-input: false}\n",
        "\n",
        "Entrenar_modelo = False #@param {type:\"boolean\"}\n",
        "#Validar_modelo = True #@param {type:\"boolean\"}\n",
        "path_modelos_entrenados = f\"/content/gdrive/My Drive/PROYECTO_PLACAS DE PETRI/RED NEURONAL/{tipo_analisis}/{tipo_patogeno}/Modelos entrenados/\"\n",
        "path_modelos_entrenados = os.listdir(path_modelos_entrenados)\n",
        "print(path_modelos_entrenados)\n",
        "# tipo analisis:\n",
        "#   1. Aguas - Deteccion\n",
        "#   2. Challenge - Deteccion\n",
        " \n",
        "# tipo patogeno:\n",
        "#   1. Candida Albicans\n",
        "#   2. Aerobios Mesofilos\n",
        "#   3. Burkholderia Cepacia\n",
        "#   4. Mohos y levaduras\n",
        "#   5. Aspergillus Brasiliensis\n",
        "#   6. Staphylococcus Aureus\n",
        "#   7. Escherichia Coli\n",
        "#   8. Staphylococcus Aureus\n",
        "#   9. Pseudomonas Aeruginosa"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYS88f-UTEAa",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "if Entrenar_modelo == False:\n",
        "  Nombre_Fichero_modelo_a_validar =  \"230-AG-AM.pt\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8m1mG095x0u",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title **HIPERPARÁMETROS:** { output-height: 100 }\n",
        "batch_size = 4 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "batch_size_test = 1 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "n_epochs = 17 #@param {type:\"slider\", min:0, max:40, step:1}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEqN5MsS68Mq",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title **PARÁMETROS - OPTIMIZADOR:**\n",
        "learning_rate = 0.01 #@param {type:\"slider\", min:0, max:0.25, step:0.01}\n",
        "momentum = 0.9 #@param {type:\"slider\", min:0.5, max:1, step:0.05}\n",
        "weight_decay = 0.0005 #@param {type:\"number\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q520l95Q82YV",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title **PARÁMETROS - FILTRO:**\n",
        "tipo_filtro = 'Rudimentario' #@param [\"Rudimentario\", \"NMS\",\"Soft-NMS\"]{allow-input: false}\n",
        "score_threshold = 0.3 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "iou_threshold = 0.15 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "dist_eucl_threshold = 85 #@param {type:\"slider\", min:0, max:100, step:5}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Hql9IURGvRt",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "749e60a1-09e1-42ba-9a85-80f53cd2bf1c"
      },
      "source": [
        "#@title ##### IDENTIFICADOR SELECCIÓN\n",
        "if tipo_analisis == \"Challenge - Deteccion\":\n",
        "  id_analisis = \"CH\"\n",
        "\n",
        "elif tipo_analisis == \"Aguas - Deteccion\":\n",
        "  id_analisis = \"AG\"\n",
        "\n",
        "if tipo_patogeno == \"Candida Albicans\":\n",
        "  id_patogeno = \"CA\"\n",
        "elif tipo_patogeno == \"Burkholderia Cepacia\":\n",
        "  id_patogeno =\"BC\"\n",
        "elif tipo_patogeno == \"Aspergillus Brasiliensis\":\n",
        "  id_patogeno =\"AB\"\n",
        "elif tipo_patogeno == \"Escherichia Coli\":\n",
        "  id_patogeno =\"EC\"\n",
        "elif tipo_patogeno == \"Pseudomonas Aeruginosa\":\n",
        "  id_patogeno = \"PA\"\n",
        "elif tipo_patogeno == \"Staphylococcus Aureus\":\n",
        "  id_patogeno =\"SA\"\n",
        "elif tipo_patogeno == \"Aerobios Mesofilos\":\n",
        "  id_patogeno =\"AM\"\n",
        "\n",
        "print(f'{tipo_analisis} - {tipo_patogeno}')\n",
        "print(id,id_analisis, id_patogeno)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aguas - Deteccion - Aerobios Mesofilos\n",
            "726 AG AM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0LeD1cGSMRC",
        "colab_type": "text"
      },
      "source": [
        "#**LIBRERIAS**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b8WIga1xFGQ",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "1fe19add-b980-4756-9e94-c5812626ad36"
      },
      "source": [
        "#@title GITHUB\n",
        "%%shell\n",
        "\n",
        "pip install cython\n",
        "# Install pycocotools, the version by default in Colab\n",
        "# has a bug fixed in https://github.com/cocodataset/cocoapi/pull/354\n",
        "# pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "pip install -U 'git+https://github.com/jdmelendez/PyCocoTools.git#subdirectory=PythonAPI'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (0.29.21)\n",
            "Collecting git+https://github.com/jdmelendez/PyCocoTools.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/jdmelendez/PyCocoTools.git to /tmp/pip-req-build-ogdb1t3_\n",
            "  Running command git clone -q https://github.com/jdmelendez/PyCocoTools.git /tmp/pip-req-build-ogdb1t3_\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (49.6.0)\n",
            "Requirement already satisfied, skipping upgrade: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (0.29.21)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools==2.0) (1.15.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp36-cp36m-linux_x86_64.whl size=266586 sha256=4b9ba53b60fc15ff30209b8adc33cdcf689b445d5b3f6c36d7ac15e3d5f7de5c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1bn6fsw9/wheels/79/68/07/613749114c98c026c7d617726f564664c577eaf1db4aa4d60e\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "  Found existing installation: pycocotools 2.0.1\n",
            "    Uninstalling pycocotools-2.0.1:\n",
            "      Successfully uninstalled pycocotools-2.0.1\n",
            "Successfully installed pycocotools-2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jT0pR14USY5L",
        "colab_type": "text"
      },
      "source": [
        "#**PREPARACIÓN DATASETS**\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkkf3JXX5c7g",
        "colab_type": "text"
      },
      "source": [
        "#### CREACION DATALOADER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7LckhAUV72-w",
        "colab": {}
      },
      "source": [
        "class MyDataLoader(torch.utils.data.Dataset):\n",
        "      def __init__(self, path_to_imgs, path_to_anns,transforms):\n",
        "        self.path_to_imags = path_to_imgs\n",
        "        self.path_to_anns = path_to_anns\n",
        "        self.imgs = list(sorted(os.listdir(path_to_imgs)))\n",
        "        self.anns = list(sorted(os.listdir(path_to_anns)))\n",
        "        self.transforms = transforms\n",
        "\n",
        "      def __getitem__(self, idx):\n",
        "        # load images ad masks\n",
        "        img_path = os.path.join(self.path_to_imags, self.imgs[idx])\n",
        "        ann_path = os.path.join(self.path_to_anns, self.anns[idx])\n",
        "\n",
        "        path_filename= Path(img_path)\n",
        "        filename=path_filename.stem\n",
        "\n",
        "        # Images \n",
        "        img = Image.open(img_path).convert(\"RGB\")               \n",
        "\n",
        "        # Annotations\n",
        "        annotation_xml = ET.parse(ann_path)\n",
        "        root = annotation_xml.getroot()\n",
        "        header = [\"xmin\",\"ymin\",\"width\",\"heigth\"]\n",
        "        boxes = []\n",
        "\n",
        "        for i in root:\n",
        "            data_string =i.text \n",
        "\n",
        "        if data_string == \"- \":\n",
        "          No_labels = True\n",
        "          size_img = img.size[1]\n",
        "          xmin = int((size_img/4))\n",
        "          ymin = int((size_img/4))\n",
        "          xmax = int((3*size_img/4))\n",
        "          ymax = int((3*size_img/4))\n",
        "          boxes.append([xmin, ymin, xmax, ymax])  \n",
        "        \n",
        "        else:\n",
        "          No_labels = False\n",
        "          data = io.StringIO(data_string.strip())\n",
        "          df = pd.read_csv(data, sep=\",\", header=None,names=header,lineterminator=\";\")        \n",
        "\n",
        "          # Obtenemos boxes          \n",
        "          for index, row in df.iterrows():\n",
        "              xmax =int((row['width']))+int((row['xmin']))\n",
        "              ymax =int((row['heigth']))+int((row['ymin']))\n",
        "              xmin =int((row['xmin']))\n",
        "              ymin =int((row['ymin']))\n",
        "              boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "          # Labels\n",
        "          n_objs = len(df.index)\n",
        "\n",
        "        # Convertimos todo en tensores\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        if No_labels == True:\n",
        "          labels = torch.zeros((1,), dtype=torch.int64)\n",
        "          iscrowd = torch.zeros((1,), dtype=torch.int64)\n",
        "        else:\n",
        "          labels = torch.ones((n_objs,), dtype=torch.int64)\n",
        "          iscrowd = torch.zeros((n_objs,), dtype=torch.int64)\n",
        "        image_id = torch.tensor([idx])\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "        \n",
        "\n",
        "        # Creamos Diccionario\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        target[\"image_id\"] = image_id\n",
        "        target[\"area\"] = area\n",
        "        target[\"iscrowd\"] = iscrowd\n",
        "        #target[\"filename\"] = filename\n",
        "\n",
        "        # Transformamos en tensor imagen y diccionario\n",
        "        if self.transforms is not None:\n",
        "          img, target = self.transforms(img, target)\n",
        "\n",
        "        return img, target #filename\n",
        "\n",
        "      def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElqGf7e7T8Bb",
        "colab_type": "text"
      },
      "source": [
        "**PATHS TRAINING Y TEST**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWqBBP2AUh24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_dir = f\"/content/gdrive/My Drive/PROYECTO_PLACAS DE PETRI/RED NEURONAL/{tipo_analisis}/{tipo_patogeno}/dataset_entrenamiento/\"  # Ruta de carpeta que contiene las clases TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvdZlZFCgccD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "f955d97a-319a-4b74-fa1f-323b35d667bd"
      },
      "source": [
        "path_img = os.path.join(path_dir, \"Images\")\n",
        "path_ann = os.path.join(path_dir, \"Annotations\")\n",
        "\n",
        "imgs_names = list(sorted(os.listdir(path_img)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-50c11a179880>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpath_ann\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Annotations\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimgs_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/My Drive/PROYECTO_PLACAS DE PETRI/RED NEURONAL/Aguas - Deteccion/Aerobios Mesofilos/dataset_entrenamiento/Images'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5O-zLJyJrkW",
        "colab_type": "text"
      },
      "source": [
        "**TRANSFORMACIONES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34-hfHlOuH2z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "16ef04ee-fac0-4358-a021-01e9b2fd74c8"
      },
      "source": [
        "%%shell\n",
        "\n",
        "# Download TorchVision repo to use some files from\n",
        "# references/detection\n",
        "# git clone https://github.com/pytorch/vision.git\n",
        "# cd vision\n",
        "# git checkout v0.3.\n",
        "# git clone https://github.com/Melendez95/vision.git\n",
        "# cd vision\n",
        "\n",
        "\n",
        "git clone https://github.com/jdmelendez/Detection-Coco.git\n",
        "cd Detection-Coco\n",
        "\n",
        "cp references/detection/utils.py ../\n",
        "cp references/detection/transforms.py ../\n",
        "cp references/detection/coco_eval.py ../\n",
        "cp references/detection/engine.py ../\n",
        "cp references/detection/coco_utils.py ../"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Detection-Coco'...\n",
            "remote: Enumerating objects: 74, done.\u001b[K\n",
            "remote: Counting objects: 100% (74/74), done.\u001b[K\n",
            "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "remote: Total 530 (delta 47), reused 0 (delta 0), pack-reused 456\u001b[K\n",
            "Receiving objects: 100% (530/530), 5.75 MiB | 4.49 MiB/s, done.\n",
            "Resolving deltas: 100% (150/150), done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cZijAmSI_q-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "import transforms as T\n",
        "\n",
        "def get_transform(train):\n",
        "    transforms = []\n",
        "    # converts the image, a PIL image, into a PyTorch Tensor\n",
        "    transforms.append(T.ToTensor())\n",
        "    if train:\n",
        "        # during training, randomly flip the training images\n",
        "        # and ground-truth for data augmentation\n",
        "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
        "    return T.Compose(transforms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjQDsPqOL1Go",
        "colab_type": "text"
      },
      "source": [
        "**APLICACION DE DATALOADER**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiNJM_I6JoFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Carga de dataset y aplicacion de transformaciones\n",
        "dataset = MyDataLoader(path_img,path_ann,get_transform(train=False))\n",
        "dataset_test = MyDataLoader(path_img,path_ann,get_transform(train=False))\n",
        "\n",
        "# Division en conjunto de training y validation\n",
        "num_train = len(dataset)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "valid_size = 0.1  # Porcentaje del set de entrenamiento usado para validación TODO\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "dataset_train = torch.utils.data.Subset(dataset, indices[split:])\n",
        "dataset_test = torch.utils.data.Subset(dataset_test, indices[:split])\n",
        "\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset_train, \n",
        "                                           batch_size=batch_size, \n",
        "                                           collate_fn=utils.collate_fn, pin_memory = True, num_workers=2)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset_test, \n",
        "                                          batch_size=batch_size_test,\n",
        "                                          collate_fn=utils.collate_fn,pin_memory = True, num_workers=2)\n",
        "\n",
        "print(\"Cantidad de imagenes de entrenamiento:\",len(dataset_train))\n",
        "print(\"Cantidad de imagenes de test:\",len(dataset_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WP7tlc52Q-U5",
        "colab_type": "text"
      },
      "source": [
        "**PLOT DE IMAGENES + ETIQUETAS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKvaI25lREXE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fig = plt.figure(figsize=(30, 30))\n",
        "\n",
        "# for i in range(4):\n",
        "#   j=randint(1,len(dataset_train))\n",
        "#   img, ann= dataset_train[j]\n",
        "  \n",
        "#   ax = fig.add_subplot(1,4, i + 1, xticks=[], yticks=[])  \n",
        "#   ax.spines['left'].set_linewidth(0)\n",
        "#   ax.spines['right'].set_linewidth(0)\n",
        "#   ax.spines['bottom'].set_linewidth(0)\n",
        "#   ax.spines['top'].set_linewidth(0) \n",
        "\n",
        "\n",
        "#   npimg=img.numpy()  \n",
        "#   plt.imshow(np.transpose(npimg,(1,2,0)))\n",
        "#   plt.show\n",
        "\n",
        "#   boxes = ann['boxes']\n",
        "#   boxes=boxes.numpy()\n",
        "#   colonias = len(boxes)\n",
        "#   ax.set_title(f\"Nº Colonias: {colonias}\",color=\"black\",fontsize=15,fontweight='bold')\n",
        "\n",
        "#   for i in boxes:\n",
        "#     xmax =int(i[2])\n",
        "#     ymax =int(i[3])\n",
        "#     xmin =int(i[0])\n",
        "#     ymin =int(i[1])\n",
        "#     width = xmax-xmin\n",
        "#     heigth = ymax-ymin\n",
        "#     rect = patches.Rectangle((xmin,ymin), width, heigth, edgecolor ='r', facecolor = 'none',linewidth=1.5)\n",
        "#     ax.add_patch(rect)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIIyfpzjSla2",
        "colab_type": "text"
      },
      "source": [
        "#**ARQUITECURA DE MODELO**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHFlGHPqtY10",
        "colab_type": "text"
      },
      "source": [
        "#### MODELO PRE-ENTRENADO\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPbIx0C2tmZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "# Cantidad de clases que tenemos (backgound + colonia)\n",
        "num_classes = 2\n",
        "\n",
        "# Obtenemos el numero de caracteristicas de entrada al clasificador\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "\n",
        "# Reemplazamos la cabecera de la red pre-trained por la nueva\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "# Cantidad maxima de objetos a detectar\n",
        "model.roi_heads.detections_per_img=600\n",
        "model.rpn.anchor_generator.sizes = ((16,), (32,), (64,), (128,), (256,))\n",
        "#model.rpn.anchor_generator.sizes = ((8,), (16,), (32,), (64,), (128,))\n",
        "model.transform.min_size = (884,)\n",
        "model.transform.max_size = 884\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kWPdNCMD4nl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(model.transform.max_size)\n",
        "# !python3 -m pip list\n",
        "# !python3 -m pip freeze > requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPdsIwhiwduA",
        "colab_type": "text"
      },
      "source": [
        "# **ENTRENAMIENTO**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SR2b2uclFY6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "23228ef8-4e49-42e6-cf2c-83d5e180e795"
      },
      "source": [
        "if Entrenar_modelo:\n",
        "  from engine import train_one_epoch, evaluate\n",
        "  import utils\n",
        "    \n",
        "  # train on the GPU or on the CPU, if a GPU is not available\n",
        "  device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "  # move model to the right device\n",
        "  model.to(device)\n",
        "\n",
        "  # construct an optimizer\n",
        "  params = [p for p in model.parameters() if p.requires_grad]\n",
        "  optimizer = torch.optim.SGD(params, lr=learning_rate,momentum=momentum, weight_decay=weight_decay)\n",
        "  #optimizer = torch.optim.Adam(params, lr=learning_rate,weight_decay=weight_decay)\n",
        "\n",
        "  # and a learning rate scheduler\n",
        "  lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=3, gamma=0.1)\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "    # train for one epoch, printing every 10 iterations\n",
        "    train_one_epoch(model, optimizer, train_loader, device, epoch, print_freq=10)\n",
        "\n",
        "    # update the learning rate\n",
        "    lr_scheduler.step()\n",
        "\n",
        "    # evaluate on the test dataset\n",
        "    evaluate(model, test_loader, device=device)  \n",
        "    \n",
        "    torch.save(model.state_dict(), f\"/content/gdrive/My Drive/PROYECTO_PLACAS DE PETRI/RED NEURONAL/{tipo_analisis}/{tipo_patogeno}/Modelos entrenados/{id}-{id_analisis}-{id_patogeno}.pt\")  \n",
        "\n",
        "    print('')\n",
        "    print('==================================================')\n",
        "    print('')\n",
        "    \n",
        "\n",
        "  print(\"FIN DEL ENTRENAMIENTO\")   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-ad80e841fc23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mEntrenar_modelo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# train on the GPU or on the CPU, if a GPU is not available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Entrenar_modelo' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88vHJLi3Bh7O",
        "colab_type": "text"
      },
      "source": [
        "# **CARGA DEL MODELO ENTRENADO**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVegHzCHT_5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if Entrenar_modelo:\n",
        "  Nombre_Fichero_modelo_a_validar = f'{id}-{id_analisis}-{id_patogeno}.pt'  \n",
        "   \n",
        "model.load_state_dict(torch.load(f\"/content/gdrive/My Drive/PROYECTO_PLACAS DE PETRI/RED NEURONAL/{tipo_analisis}/{tipo_patogeno}/Modelos entrenados/{Nombre_Fichero_modelo_a_validar}\"))\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbR9TKwp2Gr3",
        "colab_type": "text"
      },
      "source": [
        "# **EVALUACIÓN**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOXC1C8x22e1",
        "colab_type": "text"
      },
      "source": [
        "#### INFERENCIA SET IMAGENES TEST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgA91i9D25kQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Obtenemos la prediccion\n",
        "# len_dataset_test = len(dataset_test)\n",
        "\n",
        "# prediction = []\n",
        "# imgs = []\n",
        "# colonias_true_v = []\n",
        "# colonias_pred_v = []\n",
        "# inference_time=[]\n",
        "\n",
        "# # train on the GPU or on the CPU, if a GPU is not available\n",
        "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        " \n",
        "# # move model to the right device\n",
        "# model.to(device)\n",
        "\n",
        "# for i in range(len_dataset_test):\n",
        "\n",
        "#   img, ann = dataset_test[i]\n",
        "\n",
        "#   boxes = ann['boxes']\n",
        "#   boxes= boxes.numpy()\n",
        "#   colonias_true = len(boxes)\n",
        "#   colonias_true_v.append(colonias_true)\n",
        "\n",
        "#   imgs.append(img)\n",
        "#   model.eval()\n",
        "#   with torch.no_grad():\n",
        "#     start_time = time.time()\n",
        "#     prediction.append(model([img.to(device)]))\n",
        "#     end_time = time.time()\n",
        "#     inference_time.append(end_time-start_time)\n",
        "    \n",
        "#   boxes_pred = prediction[i][0][\"boxes\"]\n",
        "#   boxes_pred=boxes_pred.cpu().numpy()\n",
        "#   colonias_pred = len(boxes_pred)\n",
        "#   colonias_pred_v.append(colonias_pred)\n",
        "\n",
        "\n",
        "# print(\"\\nTiempo de inferencia medio: {:.3f} segundos\".format(sum(inference_time)/len_dataset_test))\n",
        "\n",
        "# print(\"Cantidad de colonias predichas:\",colonias_pred_v)\n",
        "# print(\"Cantidad de colonias reales:\",colonias_true_v)\n",
        "\n",
        "# #torchvision.ops.nms(boxes, scores, iou_threshold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-DV8rsoiYuf",
        "colab_type": "text"
      },
      "source": [
        "**CÁLCULO DE MÉTRICAS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N5qOQ0iiees",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # MSE, MAE , RMSE\n",
        "# MSE = metrics.mean_squared_error(colonias_true_v,colonias_pred_v)\n",
        "# RMSE = np.sqrt(MSE)\n",
        "# MAE = metrics.mean_absolute_error(colonias_true_v,colonias_pred_v)\n",
        "\n",
        "# # Media error / media colonias\n",
        "# media_real = np.mean(colonias_true_v)\n",
        "# error_media = 100 * MAE / media_real\n",
        "\n",
        "# print(f\"MSE: {MSE:.2f}\")\n",
        "# print(f\"RMSE: {RMSE:.2f}\")\n",
        "# print(f\"MAE: {MAE:.2f}\")\n",
        "# print(f\"Error: {error_media:.2f} %\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXrE46_wkEa_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Plot de regesion\n",
        "# plt.figure(figsize=(10,10))\n",
        "# plt.grid()\n",
        "# plt.title(f\"Nº Colonias (Error: {error_media:.2f} %)\",fontsize=20)\n",
        "# plt.suptitle(f\"Long.Dataset: {num_train} - MAE: {MAE:.2f} - Nº Epocas: {n_epochs}\", fontsize=10)\n",
        "# plt.xlabel(\"Realidad\",fontsize=18)\n",
        "# plt.ylabel(\"Predichas\",fontsize=18)\n",
        "# plt.scatter(colonias_true_v,colonias_pred_v,s=15)\n",
        "# maximo= max([max(colonias_true_v),max(colonias_pred_v)])\n",
        "# plt.plot([0, maximo], [0, maximo], '--k')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVhv6puMoo9k",
        "colab_type": "text"
      },
      "source": [
        "**PLOT DE RESULTADOS EN PDF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnfVFzgS3-tC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from matplotlib.backends.backend_pdf import PdfPages\n",
        "\n",
        "\n",
        "# # PLot dataframe\n",
        "# pdf = PdfPages(f'/content/gdrive/My Drive/PROYECTO_PLACAS DE PETRI/RED NEURONAL/{tipo_analisis}/{tipo_patogeno}/{id}-{tipo_patogeno} (Err-{error_media:.2f} %).pdf')\n",
        "\n",
        "# # Plot de regesion \n",
        "# plt.figure(figsize=(8,8))\n",
        "# plt.grid()\n",
        "# plt.title(f\"Nº Colonias (Error: {error_media:.2f} %)\",fontsize=20)\n",
        "# plt.suptitle(f\"Long.Dataset: {num_train} - MAE: {MAE:.2f} - Nº Epocas: {n_epochs}\", fontsize=10)\n",
        "# plt.xlabel(\"Realidad\",fontsize=18)\n",
        "# plt.ylabel(\"Predichas\",fontsize=18)\n",
        "# plt.scatter(colonias_true_v,colonias_pred_v,s=100)\n",
        "# maximo= max([max(colonias_true_v),max(colonias_pred_v)])\n",
        "# plt.plot([0, maximo], [0, maximo], '--k')\n",
        "# pdf.savefig()  # saves the current figure into a pdf page\n",
        "# plt.close()\n",
        "# #pdf.close()\n",
        "\n",
        "# #Ploteamos prediccion e imagenes\n",
        "# for i in range(len_dataset_test):\n",
        "#   fig = plt.figure(figsize=(7,7))\n",
        "#   ax = fig.add_axes([0.1,0.1,0.8,0.8],xticks=[],yticks=[])\n",
        "#   ax.spines['left'].set_linewidth(0)\n",
        "#   ax.spines['right'].set_linewidth(0)\n",
        "#   ax.spines['bottom'].set_linewidth(0)\n",
        "#   ax.spines['top'].set_linewidth(0) \n",
        "\n",
        "#   npimg=imgs[i].numpy()  \n",
        "#   plt.imshow(np.transpose(npimg,(1,2,0)))\n",
        "#   plt.show\n",
        "\n",
        "#   img, ann = dataset_test[i]\n",
        "#   boxes_true = ann['boxes']\n",
        "\n",
        "\n",
        "#   boxes = prediction[i][0][\"boxes\"]\n",
        "#   boxes=boxes.cpu().numpy()\n",
        "#   colonias = len(boxes)\n",
        "#   plt.title(f\"No Colonias: {colonias} --> Realidad: {colonias_true_v[i]}\",color=\"black\",fontsize=10,fontweight='bold')\n",
        "    \n",
        "\n",
        "#   for i in boxes:\n",
        "#     xmax =int(i[2])\n",
        "#     ymax =int(i[3])\n",
        "#     xmin =int(i[0])\n",
        "#     ymin =int(i[1])\n",
        "#     width = xmax-xmin\n",
        "#     heigth = ymax-ymin\n",
        "#     rect = patches.Rectangle((xmin,ymin), width, heigth, edgecolor ='r', facecolor = 'none',linewidth=1)\n",
        "#     ax.add_patch(rect)\n",
        "\n",
        "#   # for i in boxes_true:\n",
        "#   #   xmax =int(i[2])\n",
        "#   #   ymax =int(i[3])\n",
        "#   #   xmin =int(i[0])\n",
        "#   #   ymin =int(i[1])\n",
        "#   #   width = xmax-xmin\n",
        "#   #   heigth = ymax-ymin\n",
        "#   #   rect = patches.Rectangle((xmin,ymin), width, heigth, edgecolor ='g', facecolor = 'none',linewidth=1)\n",
        "#   #   ax.add_patch(rect)\n",
        "\n",
        "#   pdf.savefig()  # saves the current figure into a pdf page\n",
        "#   plt.close()\n",
        "\n",
        "# pdf.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PVAl4xOF6KLP"
      },
      "source": [
        "# **FILTRADO**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQGRPqWvQ8me",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title #### FUNCION DE FILTRO RUDIMENTARIO\n",
        "def filter_boxes(boxes,iou_threshold, dist_eucl_threshold):\n",
        "    \n",
        "  boxes_filt = boxes\n",
        "  deletes = 0\n",
        "  indices_delete = []\n",
        "  indice_i=0\n",
        "\n",
        "\n",
        "  for i in boxes:\n",
        "    # cantidad_colonias = len(boxes) \n",
        "    # if cantidad_colonias < 250:\n",
        "    #   iou_threshold = (iou_threshold * cantidad_colonias / 120)\n",
        "    #   if iou_threshold > 0.9:\n",
        "    #     iou_threshold = 0.25\n",
        "    # else: iou_threshold = iou_threshold\n",
        "    # print(cantidad_colonias,iou_threshold)\n",
        "    x1A = i[0]\n",
        "    y1A = i[1]\n",
        "    x2A = i[2]\n",
        "    y2A = i[3]\n",
        "\n",
        "    indice_j = 0\n",
        "    for j in boxes[indice_i:]:\n",
        "      iou = 0\n",
        "      dist_eucl = 1000\n",
        "      x1B = j[0]\n",
        "      y1B = j[1]\n",
        "      x2B = j[2]\n",
        "      y2B = j[3]\n",
        "\n",
        "      # Arriba izquierda - Abajo derecha\n",
        "      if ((x1A < x1B) and (y1A < y1B) and (x2A < x2B) and (y2A < y2B) and (x1B < x2A) and (y1B < y2A)) or ((x1A > x1B) and (y1A > y1B) and (x2A > x2B) and (y2A > y2B) and (x1A < x2B) and (y1A < y2B)):\n",
        "        x_left = max(x1A, x1B)\n",
        "        y_top = max(y1A, y1B)\n",
        "        x_right = min(x2A, x2B)\n",
        "        y_bottom = min(y2A, y2B)\n",
        "\n",
        "      # Arriba derecha\n",
        "      elif ((x1A < x1B) and (y1A > y1B) and (x2A < x2B) and (y2A > y2B) and (x1B < x2A) and (y1A < y2B)):\n",
        "        x_left = x1B\n",
        "        y_top = y1A\n",
        "        x_right = x2A\n",
        "        y_bottom = y2B\n",
        "\n",
        "      # Abajo izquierda\n",
        "      elif ((x1A > x1B) and (y1A < y1B) and (x2A > x2B) and (y2A < y2B) and (x1A < x2B) and (y1B < y2A)):\n",
        "        x_left = x1A\n",
        "        y_top = y1B\n",
        "        x_right = x2B\n",
        "        y_bottom = y2A\n",
        "\n",
        "      # Arriba\n",
        "      elif ((x1A < x1B) and (y1A > y1B) and (x2A > x2B) and (y2A > y2B) and (y1A < y2B) and (x1B < x2A)):\n",
        "        x_left = x1B\n",
        "        y_top = y1A\n",
        "        x_right = x2B\n",
        "        y_bottom = y2B\n",
        "\n",
        "      # Derecha\n",
        "      elif ((x1A < x1B) and (y1A < y1B) and (x2A < x2B) and (y2A > y2B) and (y1A < y2B) and (x1B < x2A)):\n",
        "        x_left = x1B\n",
        "        y_top = y1B\n",
        "        x_right = x2A\n",
        "        y_bottom = y2B\n",
        "\n",
        "      # Abajo\n",
        "      elif ((x1A < x1B) and (y1A < y1B) and (x2A > x2B) and (y2A < y2B) and (y1A < y2B) and (x1B < x2A)):\n",
        "        x_left = x1B\n",
        "        y_top = y1B\n",
        "        x_right = x2B\n",
        "        y_bottom = y2A\n",
        "\n",
        "      # Izquierda\n",
        "      elif ((x1A > x1B) and (y1A < y1B) and (x2A > x2B) and (y2A > y2B) and (y1A < y2B) and (x1B < x2A)):\n",
        "        x_left = x1A\n",
        "        y_top = y1B\n",
        "        x_right = x2B\n",
        "        y_bottom = y2B\n",
        "\n",
        "      # Arriba ancho\n",
        "      elif ((x1A > x1B) and (y1A > y1B) and (x2A < x2B) and (y2A > y2B) and (y1A > y2B) and (x1A < x2B)):\n",
        "        x_left = x1A\n",
        "        y_top = y1A\n",
        "        x_right = x2A\n",
        "        y_bottom = y2B\n",
        "\n",
        "      # Bajo ancho\n",
        "      elif ((x1A > x1B) and (y1A< y1B) and (x2A < x2B) and (y2A < y2B) and (y1A < y2B) and (x1A < x2B)):\n",
        "        x_left = x1A\n",
        "        y_top = y1B\n",
        "        x_right = x2A\n",
        "        y_bottom = y2A\n",
        "\n",
        "      # Izquierda ancho\n",
        "      elif ((x1A > x1B) and (y1A> y1B) and (x2A > x2B) and (y2A < y2B) and (y1A < y2B) and (x1A < x2B)):\n",
        "        x_left = x1A\n",
        "        y_top = y1A\n",
        "        x_right = x2B\n",
        "        y_bottom = y2A\n",
        "\n",
        "      # Derecha ancho\n",
        "      elif ((x1A < x1B) and (y1A> y1B) and (x2A < x2B) and (y2A < y2B) and (y1A < y2B) and (x1A < x2B)):\n",
        "        x_left = x1B\n",
        "        y_top = y1A\n",
        "        x_right = x2A\n",
        "        y_bottom = y2A\n",
        "\n",
        "      # Horizontal\n",
        "      elif ((x1A > x1B) and (y1A< y1B) and (x2A < x2B) and (y2A > y2B) and (y1A < y2B) and (x1A < x2B)):\n",
        "        x_left = x1A\n",
        "        y_top = y1B\n",
        "        x_right = x2A\n",
        "        y_bottom = y2B\n",
        "\n",
        "      # Vertical\n",
        "      elif ((x1A < x1B) and (y1A> y1B) and (x2A > x2B) and (y2A < y2B) and (y1A < y2B) and (x1A < x2B)):\n",
        "        x_left = x1B\n",
        "        y_top = y1A\n",
        "        x_right = x2B\n",
        "        y_bottom = y2A\n",
        "\n",
        "      \n",
        "      # Dentro\n",
        "      elif (x1A < x1B and y1A < y1B and x2A > x2B and y2A > y2B) or ((x1A > x1B and y1A > y1B and x2A < x2B and y2A < y2B)):\n",
        "        centroAx = x1A+(x2A - x1A) / 2\n",
        "        centroAy = y1A+(y2A - y1A) / 2\n",
        "        centroBx = x1B+(x2B - x1B) / 2\n",
        "        centroBy = y1B+(y2B - y1B) / 2\n",
        "        dist_eucl = math.sqrt((centroAx - centroBx)**2 + (centroAy - centroBy)**2)\n",
        "\n",
        "        if dist_eucl < dist_eucl_threshold:\n",
        "          boxes_filt[indice_i + indice_j][:] = [0, 0, 0, 0]\n",
        "        indice_j += 1\n",
        "        continue\n",
        "      \n",
        "      else:\n",
        "        indice_j+=1\n",
        "        continue\n",
        "\n",
        "      # The intersection of two axis-aligned bounding boxes\n",
        "      intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
        "\n",
        "      # compute the area of both AABBs\n",
        "      bb1_area = (x2A - x1A) * (y2A - y1A)\n",
        "      bb2_area = (x2B - x1B) * (y2B - y1B)\n",
        "\n",
        "      # compute the intersection over union\n",
        "      iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
        "\n",
        "      if (iou > iou_threshold):\n",
        "          boxes_filt[indice_i+indice_j][:] = [0,0,0,0]\n",
        "\n",
        "      indice_j+=1\n",
        "    indice_i+=1\n",
        "\n",
        "\n",
        "  for i in range(len(boxes_filt)):\n",
        "    result = np.all((boxes_filt[i]==0))\n",
        "    if result:\n",
        "      indices_delete.append(i)\n",
        "\n",
        "  boxes_filt=np.delete(boxes_filt,indices_delete,axis=0)\n",
        "\n",
        "  return boxes_filt\n",
        "\n",
        "\n",
        "# Solo distancia euclidea para filtro NMS con el fin de comprobar si una box esta dentro de otra\n",
        "def filter_boxes_NMS(boxes, dist_eucl_threshold):\n",
        "    \n",
        "  boxes_filt = boxes\n",
        "  deletes = 0\n",
        "  indices_delete = []\n",
        "  indice_i=0\n",
        "\n",
        "\n",
        "  for i in boxes:\n",
        "    x1A = i[0]\n",
        "    y1A = i[1]\n",
        "    x2A = i[2]\n",
        "    y2A = i[3]\n",
        "\n",
        "    indice_j = 0\n",
        "    for j in boxes[indice_i:]:\n",
        "      iou = 0\n",
        "      dist_eucl = 1000\n",
        "      x1B = j[0]\n",
        "      y1B = j[1]\n",
        "      x2B = j[2]\n",
        "      y2B = j[3]\n",
        "\n",
        "     \n",
        "      # Dentro\n",
        "      if (x1A < x1B and y1A < y1B and x2A > x2B and y2A > y2B) or ((x1A > x1B and y1A > y1B and x2A < x2B and y2A < y2B)):\n",
        "        centroAx = x1A+(x2A - x1A) / 2\n",
        "        centroAy = y1A+(y2A - y1A) / 2\n",
        "        centroBx = x1B+(x2B - x1B) / 2\n",
        "        centroBy = y1B+(y2B - y1B) / 2\n",
        "        dist_eucl = math.sqrt((centroAx - centroBx)**2 + (centroAy - centroBy)**2)\n",
        "\n",
        "        if dist_eucl < dist_eucl_threshold:\n",
        "          boxes_filt[indice_i + indice_j][:] = [0, 0, 0, 0]\n",
        "        indice_j += 1\n",
        "        continue\n",
        "      \n",
        "      else:\n",
        "        indice_j+=1\n",
        "        continue      \n",
        "\n",
        "      indice_j+=1\n",
        "    indice_i+=1\n",
        "\n",
        "\n",
        "  for i in range(len(boxes_filt)):\n",
        "    result = np.all((boxes_filt[i]==0))\n",
        "    if result:\n",
        "      indices_delete.append(i)\n",
        "\n",
        "  boxes_filt=np.delete(boxes_filt,indices_delete,axis=0)\n",
        "\n",
        "  return boxes_filt\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os2ahrsFkWqY",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title #### FUNCION DE FILTRO SOFT - NMS\n",
        "\n",
        "def soft_nms_pytorch(dets, box_scores, sigma=0.5, thresh=score_threshold, cuda=1):\n",
        "    \"\"\"\n",
        "    Build a pytorch implement of Soft NMS algorithm.\n",
        "    # Augments\n",
        "        dets:        boxes coordinate tensor (format:[y1, x1, y2, x2])\n",
        "        box_scores:  box score tensors\n",
        "        sigma:       variance of Gaussian function\n",
        "        thresh:      score thresh\n",
        "        cuda:        CUDA flag\n",
        "    # Return\n",
        "        the index of the selected boxes\n",
        "    \"\"\"\n",
        "\n",
        "    # Indexes concatenate boxes with the last column\n",
        "    N = dets.shape[0]\n",
        "    if cuda:\n",
        "        indexes = torch.arange(0, N, dtype=torch.float).cuda().view(N, 1)\n",
        "    else:\n",
        "        indexes = torch.arange(0, N, dtype=torch.float).view(N, 1)\n",
        "    dets = torch.cat((dets, indexes), dim=1)\n",
        "\n",
        "    # The order of boxes coordinate is [y1,x1,y2,x2]\n",
        "    y1 = dets[:, 0]\n",
        "    x1 = dets[:, 1]\n",
        "    y2 = dets[:, 2]\n",
        "    x2 = dets[:, 3]\n",
        "    scores = box_scores\n",
        "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
        "\n",
        "    for i in range(N):\n",
        "        # intermediate parameters for later parameters exchange\n",
        "        tscore = scores[i].clone()\n",
        "        pos = i + 1\n",
        "\n",
        "        if i != N - 1:\n",
        "            maxscore, maxpos = torch.max(scores[pos:], dim=0)\n",
        "            if tscore < maxscore:\n",
        "                dets[i], dets[maxpos.item() + i + 1] = dets[maxpos.item() + i + 1].clone(), dets[i].clone()\n",
        "                scores[i], scores[maxpos.item() + i + 1] = scores[maxpos.item() + i + 1].clone(), scores[i].clone()\n",
        "                areas[i], areas[maxpos + i + 1] = areas[maxpos + i + 1].clone(), areas[i].clone()\n",
        "\n",
        "        # IoU calculate\n",
        "        yy1 = np.maximum(dets[i, 0].to(\"cpu\").numpy(), dets[pos:, 0].to(\"cpu\").numpy())\n",
        "        xx1 = np.maximum(dets[i, 1].to(\"cpu\").numpy(), dets[pos:, 1].to(\"cpu\").numpy())\n",
        "        yy2 = np.minimum(dets[i, 2].to(\"cpu\").numpy(), dets[pos:, 2].to(\"cpu\").numpy())\n",
        "        xx2 = np.minimum(dets[i, 3].to(\"cpu\").numpy(), dets[pos:, 3].to(\"cpu\").numpy())\n",
        "        \n",
        "        w = np.maximum(0.0, xx2 - xx1 + 1)\n",
        "        h = np.maximum(0.0, yy2 - yy1 + 1)\n",
        "        inter = torch.tensor(w * h).cuda() if cuda else torch.tensor(w * h)\n",
        "        ovr = torch.div(inter, (areas[i] + areas[pos:] - inter))\n",
        "\n",
        "        # Gaussian decay\n",
        "        weight = torch.exp(-(ovr * ovr) / sigma)\n",
        "        scores[pos:] = weight * scores[pos:]\n",
        "\n",
        "    # select the boxes and keep the corresponding indexes\n",
        "    keep = dets[:, 4][scores > thresh].int()\n",
        "\n",
        "    return keep"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ttr2ec2VQ8rw",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title #### PREDICCION APLICANDO FILTRO\n",
        "\n",
        "\n",
        "\n",
        "# Obtenemos la prediccion\n",
        "len_dataset_test = len(dataset_test)\n",
        "\n",
        "prediction = []\n",
        "imgs = []\n",
        "colonias_true_v = []\n",
        "colonias_pred_v = []\n",
        "colonias_pred_filt_v = []\n",
        "inference_time=[]\n",
        "index=0\n",
        "boxes=[]\n",
        "boxes_pred_filt = []\n",
        "boxes_pred_filt_0 = []\n",
        "boxes_pred = []\n",
        "scores_pred_filt_0 = []\n",
        "filename_img_v = []\n",
        "box_ninguna_colonia_min = ((size_img/4)) \n",
        "box_ninguna_colonia_max = ((3*size_img/4)) \n",
        "\n",
        "if tipo_analisis == \"Aguas - Deteccion\":\n",
        "  size_img = 884\n",
        "else:\n",
        "  size_img = 1232\n",
        "\n",
        "for i in range(len_dataset_test):\n",
        "  index+=1\n",
        "  img, ann = dataset_test[i]\n",
        "\n",
        "  filename = ann[\"image_id\"].cpu().numpy()\n",
        "  filename = str(filename).lstrip('[').rstrip(']')\n",
        "  filename_img_v.append(imgs_names[int(filename)])\n",
        "\n",
        "  #filename_img_v.append(ann[\"filename\"])\n",
        "  boxes_0 = ann['boxes']\n",
        "  boxes_0 = boxes_0.cpu().numpy()\n",
        "  boxes.append((boxes_0))\n",
        "  colonias_true = len(boxes[i])\n",
        "\n",
        "  if colonias_true == 1:\n",
        "    if (boxes_0[0][0] == box_ninguna_colonia_min) and (boxes_0[0][1] == box_ninguna_colonia_min) and (boxes_0[0][2] == box_ninguna_colonia_max) and (boxes_0[0][3] == box_ninguna_colonia_max):\n",
        "      colonias_true = 0\n",
        "  colonias_true_v.append(colonias_true)\n",
        "\n",
        "  imgs.append(img)\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    start_time = time.time()\n",
        "    prediction.append(model([img.to(device)]))\n",
        "    end_time = time.time()\n",
        "    inference_time.append(end_time-start_time)\n",
        "    \n",
        "  boxes_pred_0 = prediction[i][0][\"boxes\"].data\n",
        "  scores_pred_0 = prediction[i][0][\"scores\"].data \n",
        "\n",
        "  #print(boxes_pred_0,scores_pred_0) \n",
        "  \n",
        "\n",
        "  # Aplicando filtro\n",
        "  # Rudimentario\n",
        "  if tipo_filtro == 'Rudimentario':\n",
        "    boxes_pred.append(boxes_pred_0.cpu().numpy())\n",
        "    scores_pred=scores_pred_0.cpu().numpy()\n",
        "    boxes_pred_filt.append(filter_boxes(boxes_pred[i],iou_threshold=iou_threshold, dist_eucl_threshold =dist_eucl_threshold))\n",
        "    \n",
        "    \n",
        "  # Non maximum supresion\n",
        "  if tipo_filtro == 'NMS':  \n",
        "    boxes_pred.append(boxes_pred_0.cpu().numpy())\n",
        "    keep = torchvision.ops.nms(boxes_pred_0, scores_pred_0, iou_threshold)\n",
        "    boxes_pred_filt_NMS = boxes_pred_0[keep,:]\n",
        "    scores_pred = scores_pred_0[keep]\n",
        "    boxes_pred_filt.append(filter_boxes_NMS(boxes_pred_filt_NMS[i], dist_eucl_threshold =dist_eucl_threshold))  \n",
        "\n",
        "  \n",
        "  # Soft NMS\n",
        "  if tipo_filtro == 'Soft-NMS':\n",
        "    boxes_pred.append(boxes_pred_0.cpu().numpy())\n",
        "    keep = soft_nms_pytorch(boxes_pred_0, scores_pred_0, cuda=1)\n",
        "    keep = keep.cpu().numpy()\n",
        "    boxes_pred_filt_0.append(boxes_pred_0.cpu().numpy()[keep])\n",
        "    scores_pred_filt_0.append(scores_pred_0.cpu().numpy()[keep])\n",
        "    boxes_pred_filt.append(filter_boxes_NMS(boxes_pred_filt_0[i], dist_eucl_threshold =dist_eucl_threshold))  \n",
        "  \n",
        "       \n",
        "  colonias_pred = len(boxes_pred_0)\n",
        "  colonias_pred_v.append(colonias_pred)\n",
        "\n",
        "  if len(boxes_pred_filt[i])==1:\n",
        "    xmax = boxes_pred_filt[i][0][2]\n",
        "    xmin = boxes_pred_filt[i][0][0]\n",
        "    if xmax-xmin<5:\n",
        "      boxes_pred_filt[i]=[]\n",
        "      \n",
        "\n",
        "  colonias_pred_filt = len(boxes_pred_filt[i])\n",
        "  colonias_pred_filt_v.append(colonias_pred_filt)\n",
        "\n",
        "\n",
        "print(\"\\nTiempo de inferencia medio: {:.3f} segundos\".format(sum(inference_time)/len_dataset_test))\n",
        "\n",
        "print(\"Cantidad de colonias predichas:\",colonias_pred_v)\n",
        "print(\"Cantidad de colonias predichas filtradas:\",colonias_pred_filt_v)\n",
        "print(\"Cantidad de colonias reales:\",colonias_true_v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSa3QZO6kff8",
        "colab_type": "text"
      },
      "source": [
        "# **RESULTADOS**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnwaFDi2EyfN",
        "colab_type": "text"
      },
      "source": [
        "#### FUNCION PARA CATALOGAR PLACAS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4gXEaQoF2VJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataframe_cataloga_placas(tipo_analisis,tipo_patogeno,colonias_true_v,colonias_pred_v,colonias_pred_filt_v,imgs_names):\n",
        "\n",
        "  placa_catalogada_real = []\n",
        "  placa_catalogada_filtrada = []\n",
        "  placa_catalogada_comparacion = []\n",
        "  placa_catalogada_como_A_enlugarde_B = []\n",
        "  placa_catalogada_como_B_enlugarde_A = []\n",
        "  placa_catalogada_como_FP = []\n",
        "  placa_catalogada_como_FN = []\n",
        "\n",
        "# ____________________________________________________________________________________\n",
        "  if tipo_analisis == \"Challenge - Deteccion\":\n",
        "    \n",
        "    for i in range(len(colonias_true_v)):\n",
        "      # Se obtiene la catalogacion tanto para la placa real como para la filtrada\n",
        "      placa_catalogada_real.append(cataloga_placas_challenge(colonias_true_v[i]))\n",
        "      placa_catalogada_filtrada.append(cataloga_placas_challenge(colonias_pred_filt_v[i]))\n",
        "\n",
        "      # Se comprueba si la catalogacion coincide. Si esta mal se comprueba el tipo de error\n",
        "      if placa_catalogada_real[i] == placa_catalogada_filtrada[i]:\n",
        "        placa_catalogada_comparacion.append(0)\n",
        "        placa_catalogada_como_A_enlugarde_B.append(0)\n",
        "        placa_catalogada_como_B_enlugarde_A.append(0)\n",
        "\n",
        "      else:\n",
        "        placa_catalogada_comparacion.append(1)\n",
        "        if placa_catalogada_filtrada[i] == \"A\":\n",
        "          placa_catalogada_como_A_enlugarde_B.append(1)\n",
        "        elif placa_catalogada_filtrada[i] == \"B\":\n",
        "          placa_catalogada_como_B_enlugarde_A.append(1) \n",
        "\n",
        "      \n",
        "    dataframe =pd.DataFrame({\"Colonias Reales\":colonias_true_v,\n",
        "                            \"Colonias Predichas\":colonias_pred_v,\n",
        "                            \"Colonias Post-Filtro\":colonias_pred_filt_v,                             \n",
        "                            \"Error Nº Colonias\":  [x1 - x2 for (x1, x2) in zip(colonias_pred_filt_v,colonias_true_v)],\n",
        "                            \"Catalogacion Real\": placa_catalogada_real,\n",
        "                            \"Catalogacion Post-Filtro\": placa_catalogada_filtrada,                             \n",
        "                            \"Fallo Catalogacion\": placa_catalogada_comparacion,\n",
        "                            \"Fallo A en lugar de B\": placa_catalogada_como_A_enlugarde_B,\n",
        "                            \"Fallo B en lugar de A\": placa_catalogada_como_B_enlugarde_A})  \n",
        "\n",
        "# ____________________________________________________________________________________\n",
        "  elif tipo_analisis == \"Aguas - Deteccion\":\n",
        "    for i in range(len(colonias_true_v)):\n",
        "\n",
        "      if colonias_true_v[i] >= 100:\n",
        "        placa_catalogada_real.append('POS')\n",
        "      else:\n",
        "        placa_catalogada_real.append('NEG')\n",
        "\n",
        "      if colonias_pred_filt_v[i] >= 100:\n",
        "        placa_catalogada_filtrada.append('POS')\n",
        "      else:        \n",
        "        placa_catalogada_filtrada.append('NEG')\n",
        "\n",
        "      if placa_catalogada_real[i] == placa_catalogada_filtrada[i]:        \n",
        "        placa_catalogada_comparacion.append('-')\n",
        "        placa_catalogada_como_FN.append('-')\n",
        "        placa_catalogada_como_FP.append('-')\n",
        "      else:\n",
        "      # Si la placa es erroena ponemos un 1\n",
        "        placa_catalogada_comparacion.append('SI')\n",
        "        if placa_catalogada_filtrada[i] == 'POS':\n",
        "          placa_catalogada_como_FP.append('SI')\n",
        "          placa_catalogada_como_FN.append('-')\n",
        "        else:\n",
        "          placa_catalogada_como_FN.append('SI')\n",
        "          placa_catalogada_como_FP.append('-')\n",
        "\n",
        "    # print(len(colonias_true_v))\n",
        "    # print(len(colonias_pred_v))\n",
        "    # print(len(colonias_pred_filt_v))\n",
        "    # print(len(placa_catalogada_real))\n",
        "    # print(len(placa_catalogada_filtrada))\n",
        "    # print(len(placa_catalogada_comparacion))\n",
        "    # print(len(placa_catalogada_como_OK_enlugarde_NoOK))\n",
        "    # print(len(placa_catalogada_como_NoOK_enlugarde_OK))\n",
        "    \n",
        "\n",
        "\n",
        "    dataframe=pd.DataFrame({\"Nombre imagen\": imgs_names,\n",
        "                            \"Colonias Reales\":colonias_true_v,\n",
        "                            \"Colonias Predichas\":colonias_pred_v,\n",
        "                            \"Colonias Post-Filtro\":colonias_pred_filt_v,\n",
        "                            \"Error Nº Colonias\": [x1 - x2 for (x1, x2) in zip(colonias_pred_filt_v,colonias_true_v)],\n",
        "                            \"Catalogacion Real\": placa_catalogada_real,\n",
        "                            \"Catalogacion Post-Filtro\": placa_catalogada_filtrada,\n",
        "                            \"Fallo Catalogacion\": placa_catalogada_comparacion,\n",
        "                            \"Falso positivo\": placa_catalogada_como_FP,\n",
        "                            \"Falso negativo\": placa_catalogada_como_FN}) \n",
        "\n",
        "  return dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Xq3gFddkib6",
        "colab_type": "text"
      },
      "source": [
        "#### CSV PLACAS CATALOGADAS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE0Ls8_enSXN",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title ####CREACION DATAFRAME\n",
        "df_colonias = dataframe_cataloga_placas(tipo_analisis,tipo_patogeno,colonias_true_v,colonias_pred_v,colonias_pred_filt_v,filename_img_v)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "display(df_colonias)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP3ktCClcQNm",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title ####MANIPULACIÓN DATAFRAME\n",
        "\n",
        "if  tipo_analisis == \"Challenge - Deteccion\":\n",
        "  pass\n",
        "elif tipo_analisis == \"Aguas - Deteccion\":\n",
        "  df_colonias_grupos_fallo = df_colonias.groupby(\"Fallo Catalogacion\")\n",
        "\n",
        "  is_FN = df_colonias.loc[:, 'Falso negativo'] == 'SI'\n",
        "  df_colonias_grupo_FN = df_colonias.loc[is_FN]\n",
        "\n",
        "  is_FP = df_colonias.loc[:, 'Falso positivo'] == 'SI'\n",
        "  df_colonias_grupo_FP = df_colonias.loc[is_FP]\n",
        " \n",
        "  df_colonias_grupo_erroneas = df_colonias_grupos_fallo.get_group(\"SI\")\n",
        "  df_colonias_grupo_correctas = df_colonias_grupos_fallo.get_group('-')\n",
        "  #display(df_colonias_grupo_erroneas)\n",
        "\n",
        "  placas_correctas = len(df_colonias_grupo_correctas)\n",
        "  placas_erroneas = len(df_colonias_grupo_erroneas)  \n",
        "  placas_erroneas_FP = len(df_colonias_grupo_FP)\n",
        "  placas_erroneas_FN = len(df_colonias_grupo_FN)  \n",
        "  #display(df_colonias_grupo_FP)\n",
        "  #display(df_colonias_grupo_FN)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b9PRejIw2Sv",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title ####RESULTADOS CATALOGACIÓN DE PLACAS\n",
        "\n",
        "\n",
        "if tipo_analisis == 'Aguas - Deteccion':\n",
        "  fig_cataloga_placas = plt.figure(figsize=(20, 10))\n",
        "  ax1 = fig_cataloga_placas.add_subplot(121)\n",
        "  ax2 = fig_cataloga_placas.add_subplot(122)\n",
        "  fig_cataloga_placas.subplots_adjust(wspace=0)\n",
        "\n",
        "  ratios1 = [placas_correctas,placas_erroneas]\n",
        "\n",
        "  explode = [0, 0]\n",
        "  angle = -180 * ratios1[0]\n",
        "  ax1.set_title('RESUMEN CATALOGACIÓN PLACAS')\n",
        "  ax1.pie(ratios1, autopct=f'%1.1f%%', startangle=angle,\n",
        "          labels=ratios1, explode=explode,textprops={'fontsize': 20})\n",
        "  ax1.legend((f'PLACAS BIEN CATALOGADAS', 'PLACAS MAL CATALOGADAS'))\n",
        "\n",
        "\n",
        "  ratios = [placas_erroneas_FP,placas_erroneas_FN]\n",
        "  colors = [[.2, .8, .5], [.8, .3, .3]]\n",
        "  bottom=0\n",
        "  width=0.05\n",
        "\n",
        "  for j in range(len(ratios)):\n",
        "      height = ratios[j]\n",
        "      ax2.bar(0, height, width, bottom=bottom, color=colors[j])\n",
        "      ypos = bottom + ax2.patches[j].get_height() / 2\n",
        "      bottom += height\n",
        "      if ratios[j] !=0:\n",
        "        ax2.text(0, ypos, f\"%d%% - {ratios[j]}\" % (ratios[j]/sum(ratios) * 100),\n",
        "                ha='center',fontsize=20)\n",
        "      \n",
        "  ax2.set_title('DESGLOSE PLACAS MAL CATALOGADAS')\n",
        "  ax2.legend(('FALSOS POSITIVOS', 'FALSOS NEGATIVOS'))\n",
        "  ax2.axis('off')\n",
        "  ax2.set_xlim(- 2.5 * width, 2.5 * width)\n",
        "\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4PhjyMSHgZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ratios1 = pd.DataFrame({'Resultado': ['Bien','Mal'],\n",
        "#                         'Cantidad placas': ratios1})\n",
        "# #display(ratios1)\n",
        "# # plot the dataset, referencing dataframe column names\n",
        "# import altair as alt\n",
        "# alt.Chart(ratios1).mark_bar().encode( \n",
        "#   x='Cantidad placas' ,\n",
        "#   y='Resultado',\n",
        "#   color='Resultado'\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlLZN1u0j0NA",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title ####PLACAS MAL CATALOGADAS\n",
        "\n",
        "indices_erroneas = df_colonias_grupo_erroneas.index\n",
        "\n",
        "# #print(indices_erroneas)\n",
        "\n",
        "# for i in indices_erroneas:\n",
        "#   index=0\n",
        "#   xmax_filt = []\n",
        "#   ymax_filt = []\n",
        "#   xmin_filt = []\n",
        "#   ymin_filt = []\n",
        "\n",
        "#   fig = plt.figure(figsize=(10,10))  \n",
        "#   ax = fig.add_axes([0.1,0.1,0.8,0.8],xticks=[],yticks=[])\n",
        "#   ax.spines['left'].set_linewidth(0)\n",
        "#   ax.spines['right'].set_linewidth(0)\n",
        "#   ax.spines['bottom'].set_linewidth(0)\n",
        "#   ax.spines['top'].set_linewidth(0) \n",
        "\n",
        "#   npimg=imgs[i].numpy()  \n",
        "#   plt.imshow(np.transpose(npimg,(1,2,0)))\n",
        "#   plt.show\n",
        "\n",
        "#   colonias = len(boxes_pred_filt[i])\n",
        "#   plt.title(f\"No Colonias: {colonias} --> Realidad: {colonias_true_v[i]}\",color=\"black\",fontsize=10,fontweight='bold')\n",
        "\n",
        "#   for j in boxes_pred_filt[i]:\n",
        "    \n",
        "#     xmax_filt.append(int(j[2]))\n",
        "#     ymax_filt.append(int(j[3]))\n",
        "#     xmin_filt.append(int(j[0]))\n",
        "#     ymin_filt.append(int(j[1]))\n",
        "#     width = xmax_filt[index]-xmin_filt[index]    \n",
        "#     heigth = ymax_filt[index]-ymin_filt[index]\n",
        "#     rect = patches.Rectangle((xmin_filt[index],ymin_filt[index]), width, heigth, edgecolor ='r', facecolor = 'none',linewidth=1)\n",
        "#     #ax.annotate(f\"{index}\",(xmin,ymin),color='b')\n",
        "#     ax.add_patch(rect)\n",
        "#     index+=1\n",
        "\n",
        "  \n",
        "#   for z in boxes[i]:\n",
        "#     no_pintar = 0\n",
        "    \n",
        "#     xmax =int(z[2])\n",
        "#     ymax =int(z[3])\n",
        "#     xmin =int(z[0])\n",
        "#     ymin =int(z[1])\n",
        "\n",
        "#     for w in range(len(boxes_pred_filt[i])):\n",
        "#       if (np.abs(xmax - xmax_filt[w]) < 10) and (np.abs(ymax - ymax_filt[w]) < 10) and (np.abs(xmin - xmin_filt[w]) < 10) and (np.abs(ymin - ymin_filt[w]) < 10):\n",
        "#         no_pintar = 1\n",
        "#         continue\n",
        "\n",
        "#     if no_pintar:\n",
        "#       continue\n",
        "#     width = xmax-xmin\n",
        "#     heigth = ymax-ymin\n",
        "#     rect = patches.Rectangle((xmin,ymin), width, heigth, edgecolor ='b', facecolor = 'none',linewidth=1)\n",
        "#     #ax.annotate(f\"{index}\",(xmin,ymin),color='b')\n",
        "#     ax.add_patch(rect)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eljhvp9rknX3",
        "colab_type": "text"
      },
      "source": [
        "#### METRICAS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uq9m28J-LaRF",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "a0c87f85-869e-4819-9ffe-8ecde76428dc"
      },
      "source": [
        "#@title ####ERRORES\n",
        "MSE = metrics.mean_squared_error(colonias_true_v,colonias_pred_filt_v)\n",
        "RMSE = np.sqrt(MSE)\n",
        "MAE = metrics.mean_absolute_error(colonias_true_v,colonias_pred_filt_v)\n",
        "\n",
        "# Media error / media colonias\n",
        "media_real = np.mean(colonias_true_v)\n",
        "error_media = 100 * MAE / media_real\n",
        "\n",
        "print(f\"MSE: {MSE:.2f}\")\n",
        "print(f\"RMSE: {RMSE:.2f}\")\n",
        "print(f\"MAE: {MAE:.2f}\")\n",
        "print(f\"Error: {error_media:.2f} %\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-0250c30aa8b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#@title ####ERRORES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mMSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolonias_true_v\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolonias_pred_filt_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mRMSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMSE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mMAE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolonias_true_v\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolonias_pred_filt_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'colonias_true_v' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "00wfjTLPmQSy",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "outputId": "09f83b81-8107-46aa-ca88-c84248885e96"
      },
      "source": [
        "#@title #### PREDICHAS VS REALIDAD\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.grid()\n",
        "plt.title(f\"Nº Colonias (Error: {error_media:.2f} %)\",fontsize=20)\n",
        "plt.suptitle(f\"Long.Dataset: {num_train} - MAE: {MAE:.2f} - Nº Epocas: {n_epochs}\", fontsize=10)\n",
        "plt.xlabel(\"Realidad\",fontsize=18)\n",
        "plt.ylabel(\"Predichas\",fontsize=18)\n",
        "plt.scatter(colonias_true_v,colonias_pred_v,s=15,label=\"Sin filtrar\")\n",
        "plt.scatter(colonias_true_v,colonias_pred_filt_v,s=15,c='r',label=\"Filtradas\")\n",
        "plt.legend()\n",
        "maximo= max([max(colonias_true_v),max(colonias_pred_v)])\n",
        "plt.plot([0, maximo], [0, maximo], '--k')\n",
        "\n",
        "import altair as alt\n",
        "alt.Chart(df_colonias).mark_circle(size=20).encode(\n",
        "    x='Colonias Reales',\n",
        "    y='Colonias Post-Filtro',\n",
        "    color='Fallo Catalogacion',\n",
        "    tooltip=['Fallo Catalogacion','Colonias Post-Filtro','Colonias Reales','Nombre imagen']\n",
        ").interactive()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-cfd201a037d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Nº Colonias (Error: {error_media:.2f} %)\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Long.Dataset: {num_train} - MAE: {MAE:.2f} - Nº Epocas: {n_epochs}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Realidad\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'error_media' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pYCjZVfLa_2b"
      },
      "source": [
        "# **RESULTADOS EN PDF (POST - FILTRADO)**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "74vsbsjea_2n",
        "colab": {}
      },
      "source": [
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "\n",
        "pdf = PdfPages(f'/content/gdrive/My Drive/PROYECTO_PLACAS DE PETRI/RED NEURONAL/{tipo_analisis}/{tipo_patogeno}/{id}-{id_analisis}-{tipo_patogeno}-(Err-{error_media:.2f}).pdf')\n",
        "\n",
        "# Primera pagina - titulo \n",
        "fig = plt.figure(figsize=(16,9))\n",
        "ax=fig.add_subplot(111)\n",
        "ax.text(5,5,f'{tipo_analisis}\\n\\n{tipo_patogeno}\\n\\n\\nModelo:{Nombre_Fichero_modelo_a_validar}',horizontalalignment='center', verticalalignment='center',fontsize=30)\n",
        "ax.axis([0,10,0,10])\n",
        "ax.grid(False)\n",
        "ax.spines['left'].set_linewidth(0)\n",
        "ax.spines['right'].set_linewidth(0)\n",
        "ax.spines['bottom'].set_linewidth(0)\n",
        "ax.spines['top'].set_linewidth(0)\n",
        "plt.axis('off')\n",
        "pdf.savefig()  # saves the current figure into a pdf page\n",
        "plt.close()\n",
        "\n",
        "# Plot de regesion \n",
        "plt.figure(figsize=(8,8))\n",
        "plt.grid()\n",
        "plt.title(f\"Nº Colonias (Error: {error_media:.2f} %)\",fontsize=20)\n",
        "plt.suptitle(f\"Filtro utilizado: {tipo_filtro} - IOU Thres {iou_threshold} - Dist.Euclidea Thresh: {dist_eucl_threshold} - Score Thresh: {score_threshold}\\nMétricas: MAE: {MAE:.2f} - Media colonias: {media_real:.2f}\", fontsize=10)\n",
        "plt.xlabel(\"Realidad\",fontsize=18)\n",
        "plt.ylabel(\"Predichas\",fontsize=18)\n",
        "plt.scatter(colonias_true_v,colonias_pred_v,s=15,label=\"Sin filtrar\")\n",
        "plt.scatter(colonias_true_v,colonias_pred_filt_v,s=15,c='r',label=\"Filtradas\")\n",
        "plt.legend()\n",
        "maximo= max([max(colonias_true_v),max(colonias_pred_v)])\n",
        "plt.plot([0, maximo], [0, maximo], '--k')\n",
        "pdf.savefig()  # saves the current figure into a pdf page\n",
        "plt.close()\n",
        "#pdf.close()\n",
        "\n",
        "# Plot graficos catalogacion de placas\n",
        "if tipo_analisis == 'Aguas - Deteccion':\n",
        "  fig = plt.figure(figsize=(10, 5))\n",
        "  ax1 = fig.add_subplot(121)\n",
        "  ax2 = fig.add_subplot(122)\n",
        "  fig.subplots_adjust(wspace=0)\n",
        "\n",
        "  ratios = [placas_correctas,placas_erroneas]\n",
        "  explode = [0, 0]\n",
        "  angle = -180 * ratios[0]\n",
        "  ax1.set_title('RESUMEN CATALOGACIÓN PLACAS')\n",
        "  ax1.pie(ratios, autopct='%1.1f%%', startangle=angle,\n",
        "          labels=ratios, explode=explode,textprops={'fontsize': 20})\n",
        "  ax1.legend(('PLACAS BIEN CATALOGADAS', 'PLACAS MAL CATALOGADAS'))\n",
        "\n",
        "\n",
        "  ratios = [placas_erroneas_FP,placas_erroneas_FN]\n",
        "  colors = [[.2, .8, .5], [.8, .3, .3]]\n",
        "  width=0.01\n",
        "\n",
        "  for j in range(len(ratios)):\n",
        "      height = ratios[j]\n",
        "      ax2.bar(0, height, 0.015, bottom=bottom, color=colors[j])\n",
        "      ypos = bottom + ax2.patches[j].get_height() / 2\n",
        "      bottom += height\n",
        "      if ratios[j] !=0:\n",
        "        ax2.text(0, ypos,f\"%d%% - {ratios[j]}\" % (ratios[j]/sum(ratios) * 100),\n",
        "                ha='center',fontsize=20)\n",
        "      \n",
        "  ax2.set_title('DESGLOSE PLACAS MAL CATALOGADAS')\n",
        "  ax2.legend(('FALSOS POSITIVOS', 'FALSOS NEGATIVOS'))\n",
        "  ax2.axis('off')\n",
        "  ax2.set_xlim(- 2.5 * width, 2.5 * width)\n",
        "  pdf.savefig()  # saves the current figure into a pdf page\n",
        "  plt.close()\n",
        "\n",
        "\n",
        "# Plot dataframe\n",
        "# fig = plt.figure(figsize=(16,9))\n",
        "# ax=fig.add_subplot(111)\n",
        "# ax.axis([0,10,0,10])\n",
        "# ax.grid(False)\n",
        "# ax.spines['left'].set_linewidth(0)\n",
        "# ax.spines['right'].set_linewidth(0)\n",
        "# ax.spines['bottom'].set_linewidth(0)\n",
        "# ax.spines['top'].set_linewidth(0)\n",
        "# plt.axis('off')\n",
        "df_colonias.plot()\n",
        "pdf.savefig()  # saves the current figure into a pdf page\n",
        "plt.close()\n",
        "\n",
        "#Ploteamos prediccion e imagenes\n",
        "for i in indices_erroneas:\n",
        "  fig = plt.figure(figsize=(7,7))\n",
        "  ax = fig.add_axes([0.1,0.1,0.8,0.8],xticks=[],yticks=[])\n",
        "  ax.spines['left'].set_linewidth(0)\n",
        "  ax.spines['right'].set_linewidth(0)\n",
        "  ax.spines['bottom'].set_linewidth(0)\n",
        "  ax.spines['top'].set_linewidth(0) \n",
        "\n",
        "  npimg=imgs[i].numpy()  \n",
        "  plt.imshow(np.transpose(npimg,(1,2,0)))\n",
        "  plt.show\n",
        "      \n",
        "  colonias = len(boxes_pred_filt[i])\n",
        "  plt.title(f\"No Colonias: {colonias} --> Realidad: {colonias_true_v[i]} --> MAL CATALOGADA\\n\\nImagen: {filename_img_v[i]}\",color=\"black\",fontsize=10,fontweight='bold')\n",
        "    \n",
        "  index=0;\n",
        "  for i in boxes_pred_filt[i]:\n",
        "    index+=1\n",
        "    xmax =int(i[2])\n",
        "    ymax =int(i[3])\n",
        "    xmin =int(i[0])\n",
        "    ymin =int(i[1])\n",
        "    width = xmax-xmin\n",
        "    heigth = ymax-ymin\n",
        "    rect = patches.Rectangle((xmin,ymin), width, heigth, edgecolor ='r', facecolor = 'none',linewidth=1)\n",
        "    #ax.annotate(f\"{index}\",(xmin,ymin),color='b')\n",
        "    ax.add_patch(rect)\n",
        "\n",
        "  pdf.savefig()  # saves the current figure into a pdf page\n",
        "  plt.close()\n",
        "\n",
        "for i in range(len_dataset_test):\n",
        "  index=0\n",
        "  xmax_filt = []\n",
        "  ymax_filt = []\n",
        "  xmin_filt = []\n",
        "  ymin_filt = []\n",
        "\n",
        "  if i in indices_erroneas:\n",
        "    continue\n",
        "\n",
        "  fig = plt.figure(figsize=(7,7))\n",
        "  ax = fig.add_axes([0.1,0.1,0.8,0.8],xticks=[],yticks=[])\n",
        "  ax.spines['left'].set_linewidth(0)\n",
        "  ax.spines['right'].set_linewidth(0)\n",
        "  ax.spines['bottom'].set_linewidth(0)\n",
        "  ax.spines['top'].set_linewidth(0) \n",
        "\n",
        "  npimg=imgs[i].numpy()  \n",
        "  plt.imshow(np.transpose(npimg,(1,2,0)))\n",
        "  plt.show\n",
        "      \n",
        "  colonias = len(boxes_pred_filt[i])\n",
        "  plt.title(f\"No Colonias: {colonias} --> Realidad: {colonias_true_v[i]}\\n\\nImagen: {filename_img_v[i]}\",color=\"black\",fontsize=10,fontweight='bold')\n",
        "    \n",
        "  for j in boxes_pred_filt[i]:\n",
        "    \n",
        "    xmax_filt.append(int(j[2]))\n",
        "    ymax_filt.append(int(j[3]))\n",
        "    xmin_filt.append(int(j[0]))\n",
        "    ymin_filt.append(int(j[1]))\n",
        "    width = xmax_filt[index]-xmin_filt[index]    \n",
        "    heigth = ymax_filt[index]-ymin_filt[index]\n",
        "    rect = patches.Rectangle((xmin_filt[index],ymin_filt[index]), width, heigth, edgecolor ='r', facecolor = 'none',linewidth=1)\n",
        "    #ax.annotate(f\"{index}\",(xmin,ymin),color='b')\n",
        "    ax.add_patch(rect)\n",
        "    index+=1\n",
        "\n",
        "  \n",
        "  # for z in boxes[i]:\n",
        "  #   no_pintar = 0\n",
        "    \n",
        "  #   xmax =int(z[2])\n",
        "  #   ymax =int(z[3])\n",
        "  #   xmin =int(z[0])\n",
        "  #   ymin =int(z[1])\n",
        "\n",
        "  #   for w in range(len(boxes_pred_filt[i])):\n",
        "  #     if (np.abs(xmax - xmax_filt[w]) < 20) and (np.abs(ymax - ymax_filt[w]) < 20) and (np.abs(xmin - xmin_filt[w]) < 20) and (np.abs(ymin - ymin_filt[w]) < 20):\n",
        "  #       no_pintar = 1\n",
        "  #       continue\n",
        "\n",
        "  #   if no_pintar:\n",
        "  #     continue\n",
        "  #   width = xmax-xmin\n",
        "  #   heigth = ymax-ymin\n",
        "  #   rect = patches.Rectangle((xmin,ymin), width, heigth, edgecolor ='b', facecolor = 'none',linewidth=1)\n",
        "  #   #ax.annotate(f\"{index}\",(xmin,ymin),color='b')\n",
        "  #   ax.add_patch(rect)\n",
        "\n",
        "  pdf.savefig()  # saves the current figure into a pdf page\n",
        "  plt.close()\n",
        "\n",
        "pdf.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuVkYYHLFCiZ",
        "colab_type": "text"
      },
      "source": [
        "**GUARDAMOS INFORMACION EN TXT**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L290vCw8FJd1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file = open(f\"/content/gdrive/My Drive/PROYECTO_PLACAS DE PETRI/RED NEURONAL/{tipo_analisis}/{tipo_patogeno}/training_info.txt\",\"a\")\n",
        "file.write(f\"\\n{error_media:.2f},{MSE:.2f},{RMSE:.2f},{MAE:.2f},{media_real:.2f},{batch_size},{learning_rate},{momentum},{weight_decay},{n_epochs},{num_train}\") \n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITiw9Bije6HB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Informacion acumulada en el txt\n",
        "dataframe = pd.read_csv(f\"/content/gdrive/My Drive/PROYECTO_PLACAS DE PETRI/RED NEURONAL/{tipo_analisis}/{tipo_patogeno}/training_info.txt\")\n",
        "dataframe\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYGR7tStpHej",
        "colab_type": "text"
      },
      "source": [
        "REQUIREMENTS.TXT\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKxnyM1kpQLf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "b8b38378-ba13-47b8-b1e9-defb688643e2"
      },
      "source": [
        "import pkg_resources\n",
        "import types\n",
        "def get_imports():\n",
        "    for name, val in globals().items():\n",
        "        if isinstance(val, types.ModuleType):\n",
        "            # Split ensures you get root package, \n",
        "            # not just imported function\n",
        "            name = val.__name__.split(\".\")[0]\n",
        "\n",
        "        elif isinstance(val, type):\n",
        "            name = val.__module__.split(\".\")[0]\n",
        "\n",
        "        # Some packages are weird and have different\n",
        "        # imported names vs. system/pip names. Unfortunately,\n",
        "        # there is no systematic way to get pip names from\n",
        "        # a package's imported name. You'll have to add\n",
        "        # exceptions to this list manually!\n",
        "        poorly_named_packages = {\n",
        "            \"PIL\": \"Pillow\",\n",
        "            \"sklearn\": \"scikit-learn\"\n",
        "        }\n",
        "        if name in poorly_named_packages.keys():\n",
        "            name = poorly_named_packages[name]\n",
        "\n",
        "        yield name\n",
        "imports = list(set(get_imports()))\n",
        "\n",
        "# The only way I found to get the version of the root package\n",
        "# from only the name of the package is to cross-check the names \n",
        "# of installed packages vs. imported packages\n",
        "requirements = []\n",
        "for m in pkg_resources.working_set:\n",
        "    if m.project_name in imports and m.project_name!=\"pip\":\n",
        "        requirements.append((m.project_name, m.version))\n",
        "\n",
        "for r in requirements:\n",
        "    print(\"{}=={}\".format(*r))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torchvision==0.7.0+cu101\n",
            "torch==1.6.0+cu101\n",
            "scikit-learn==0.22.2.post1\n",
            "Pillow==7.0.0\n",
            "pathlib==1.0.1\n",
            "pandas==1.0.5\n",
            "numpy==1.18.5\n",
            "matplotlib==3.2.2\n",
            "google==2.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}